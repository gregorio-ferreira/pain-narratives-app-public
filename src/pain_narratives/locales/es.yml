# Spanish (es_new.yml) - Plataforma de EvaluaciÃ³n AINarratives - LocalizaciÃ³n Completa
app:
  title: "ğŸ¥ Plataforma de EvaluaciÃ³n AINarratives"
  tagline: "Herramienta para facilitar la evaluaciÃ³n del dolor gracias a la inteligencia artificial"
  welcome_message: "ğŸ‘‹ Â¡Bienvenido/a l AINarratives!"
  
sidebar:
  header: "âš™ï¸ ConfiguraciÃ³n"
  language_select: "Idioma / Language"
  openai_api_key: "Clave API de OpenAI"
  api_key_help: "Introduzca su clave API de OpenAI para habilitar evaluaciones con IA"
  use_database: "ğŸ’¾ Usar Base de Datos"
  database_help: "Habilitar para guardar resultados en la base de datos PostgreSQL"
  model_selection: "ğŸ¤– SelecciÃ³n de Modelo"
  model_help: "Elija el modelo de OpenAI para la evaluaciÃ³n"
  temperature: "ğŸŒ¡ï¸ Temperatura"
  temperature_help: "Controla la aleatoriedad (0.0 = determinÃ­stico, 1.0 = muy aleatorio)"
  max_tokens: "ğŸ“ MÃ¡ximo de Tokens"
  max_tokens_help: "NÃºmero mÃ¡ximo de tokens en la respuesta"
  login_section: "ğŸ” Inicio de SesiÃ³n"
  username: "Nombre de Usuario"
  username_help: "Introduzca su nombre de usuario"
  login_button: "ğŸ”‘ Iniciar SesiÃ³n"
  logout_button: "ğŸšª Cerrar SesiÃ³n"
  password: "ContraseÃ±a"
  refresh_button: "ğŸ”„ Actualizar"
  refresh_groups_button: "ğŸ”„ Actualizar Grupos"
  refresh_groups_help: "Actualizar manualmente la lista de grupos de evaluaciÃ³n si es necesario"
  evaluation_groups: "Grupos de evaluaciÃ³n"
  select_group: "Seleccionar un grupo de evaluaciÃ³n"
  select_group_help: "Seleccione un grupo de evaluaciÃ³n para organizar sus evaluaciones"
  no_groups_warning: "âš ï¸ No hay grupos de evaluaciÃ³n disponibles."
  create_group_info: "ğŸ§ª Â¡Cree un grupo de evaluaciÃ³n en la pestaÃ±a **GestiÃ³n** para comenzar!"
  groups_count: "{count} grupo(s) disponible(s)"

auth:
  login_required: "ğŸ”’ Por favor inicie sesiÃ³n para acceder a esta secciÃ³n."
  username_password_required: "nombre de usuario y contraseÃ±a"
  authenticating: "Autenticando..."
  welcome_user: "âœ… Â¡Bienvenido/a, {username}!"
  invalid_credentials: "âŒ Nombre de usuario o contraseÃ±a invÃ¡lidos"
  authentication_error: "âŒ Error de autenticaciÃ³n: {error}"
  admin_access: "ğŸ”‘ Acceso de Administrador"
  user_access: "ğŸ‘¥ Acceso de Usuario"
  need_help: "â„¹ï¸ Â¿Necesita Ayuda?"
  first_time_info: |
    **Â¿Primera vez aquÃ­?**
    Consulte la pÃ¡gina principal para una descripciÃ³n general de la plataforma.

    **Â¿OlvidÃ³ sus credenciales?**
    Contacte a su administrador del sistema.

    **Â¿Necesita una cuenta?**
    Solicite a su administrador que le cree una.

tabs:
  narrative_dimensions: "ğŸ¯ Narrativas y Dimensiones"
  pain_assessment: "ğŸ¥ EvaluaciÃ³n"
  batch_evaluation: "ğŸ“Š EvaluaciÃ³n por Lotes"
  analytics: "ğŸ“ˆ AnalÃ­ticas"
  questionnaires: "ğŸ“‹ Cuestionarios"
  management: "âš™ï¸ GestiÃ³n"
  help: "â“ Ayuda"

narrative_dimensions:
  header: "ğŸ¯ Narrativas y Dimensiones"
  description: "EvalÃºe mÃºltiples narrativas dimensiones de las narrativas de dolor usando  IA"
  narrative_input: "ğŸ“ IntroducciÃ³n de la Narrativa"
  narrative_placeholder: "Por favor, introduzca  aquÃ­ el texto de la narrativa de dolor..."
  narrative_help: "Introduzca  la narrativa de dolor a evaluar "
  evaluation_type: "ğŸ”¬ Tipo de EvaluaciÃ³n"
  single_evaluation: "EvaluaciÃ³n Ãšnica"
  multiple_evaluation: "Evaluaciones MÃºltiples (Prueba de Consistencia)"
  num_evaluations: "NÃºmero de Evaluaciones"
  num_evaluations_help: "CuÃ¡ntas veces evaluar la misma narrativa para anÃ¡lisis de consistencia"
  create_new_experiment: "ğŸ§ª Crear Nuevo Experimento"
  experiment_help: "Crear una nueva entrada de experimento en la base de datos"
  evaluate_button: "ğŸš€ Evaluar Narrativa"
  evaluating_message: "ğŸ”„ Evaluando narrativa..."
  evaluation_complete: "âœ… Â¡EvaluaciÃ³n completada!"
  evaluation_error: "âŒ La evaluaciÃ³n fallÃ³"
  load_existing_narrative: "Cargar narrativa existente"
  new_narrative: "Nueva narrativa"
  upload_narrative_file: "Subir narrativa ( Solo formato .txt)"
  enter_modify_narrative: "Introducir o modificar la narrativa "
  save_narrative_button: "ğŸ’¾ Guardar Narrativa en BD"
  narrative_saved: "Narrativa guardada con ID {narrative_id}"
  failed_save_narrative: "Error al guardar narrativa: {error}"
  admin_mode_info: "ğŸ‘‘ **Modo Administrador**: Puede crear grupos de evaluaciÃ³n con prompts personalizados en la pestaÃ±a GestiÃ³n."
  no_group_selected: "âš ï¸ **NingÃºn grupo de evaluaciÃ³n seleccionado**"
  get_started_info: |
    ğŸ§ª **Comenzar:**
    1. **Usuarios regulares**: Seleccione un grupo de evaluaciÃ³n de la barra lateral
    2. **Administradores**: Cree o seleccione un grupo de evaluaciÃ³n desde la pestaÃ±a GestiÃ³n
    Una vez que haya seleccionado un grupo de evaluaciÃ³n, puede personalizar las dimensiones de evaluaciÃ³n aquÃ­.
  selected_group: "ğŸ“‹ **Grupo de evaluaciÃ³n seleccionado**: {group_id}"
  customize_dimensions: "### ğŸ“ Personalizar Dimensiones de EvaluaciÃ³n"
  customize_info: "ğŸ’¡ Modifique las dimensiones de evaluaciÃ³n existentes si lo desea, o aÃ±ada otras de su interÃ©s "
  dimensions_ready_button: "âœ… DefiniciÃ³n de Dimensiones Lista"
  fix_dimension_ranges: "âŒ Por favor corrija los rangos de dimensiÃ³n antes de continuar."

pain_assessment:
  header: "ğŸ¥ EvaluaciÃ³n de las dimensiones"
  description: "EvalÃºe narrativas de dolor individuales usando las dimensiones configuradas"
  setup_required: "â„¹ï¸ **ConfiguraciÃ³n Requerida**"
  setup_instructions: |
    Para usar las funciones de evaluaciÃ³n, configure su conexiÃ³n OpenAI:

    1. Ingrese su clave API de OpenAI en la barra lateral (o asegÃºrese de que estÃ© configurada en su entorno)
    2. Seleccione su modelo preferido y configuraciones de temperatura
    3. Haga clic en **"Inicializar Conexiones"** para comenzar a evaluar narrativas

    Una vez configurado, podrÃ¡ probar narrativas individuales y ver resultados de evaluaciÃ³n en tiempo real.
  no_group_selected: "âš ï¸ NingÃºn grupo de evaluaciÃ³n seleccionado"
  evaluation_group_required: |
    ğŸ§ª **Grupo de evaluaciÃ³n Requerido**

    Para ejecutar evaluaciones, necesita:
    1. Ir a la pestaÃ±a **âš™ï¸ GestiÃ³n**
    2. Crear un nuevo grupo de evaluaciÃ³n
    3. Volver aquÃ­ para ejecutar evaluaciones

    Los grupos de evaluaciÃ³n ayudan a organizar su investigaciÃ³n y asociar evaluaciones con estudios especÃ­ficos.
  current_narrative: "Narrativa Actual"
  narrative_required: "Por favor proporcione una narrativa de dolor en la pestaÃ±a 'Narrativas y Dimensiones'."
  pain_narrative_label: "Narrativa de Dolor"
  max_tokens: "Tokens MÃ¡ximos"
  number_evaluations: "NÃºmero de Evaluaciones"
  number_evaluations_help: "Para pruebas de consistencia"
  evaluate_button: "ğŸš€ Evaluar"
  rerun_button: "ğŸ” Re-ejecutar"
  evaluating_narrative: "Evaluando narrativa..."

questionnaires:
  header: "ğŸ“‹ Cuestionarios"
  description: |
    â„¹ï¸ **AnÃ¡lisis de Cuestionarios**

    Esta funciÃ³n le permite ejecutar cuestionarios estandarizados usando la narrativa actual.
    
    **Cuestionarios Disponibles:**
    - **PCS (Escala de CatastrofizaciÃ³n del Dolor)**: EvalÃºa patrones de pensamiento catastrÃ³fico relacionados con la experiencia del dolor
    - **BPI-IS (Inventario Breve del Dolor - Escala de Interferencia)**: EvalÃºa la interferencia del dolor con las actividades diarias y la intensidad del dolor
    - **TSK-11SV (Escala de Tampa de Kinesiofobia - VersiÃ³n Corta)**: Mide el miedo al movimiento y la evitaciÃ³n de actividades debido al dolor
    
    **CÃ³mo funciona:**
    1. Ingrese o seleccione una narrativa de dolor
    2. Elija un cuestionario del menÃº desplegable
    3. Haga clic en "Ejecutar Cuestionario" para obtener respuestas generadas por IA
    4. Vea puntuaciones detalladas y anÃ¡lisis
    
    El modelo de IA analizarÃ¡ la narrativa y proporcionarÃ¡ puntuaciones basadas en el marco validado del cuestionario.
  select_questionnaire: "Seleccionar cuestionario"
  select_questionnaires: "Seleccionar cuestionarios"
  select_at_least_one: "Seleccione al menos un cuestionario para ejecutar."
  selected_questionnaires_label: "Cuestionarios Seleccionados"
  narrative_required: "Por favor proporcione una narrativa de dolor en la pestaÃ±a 'Narrativas y Dimensiones'."
  pain_narrative_label: "Narrativa de Dolor"
  run_questionnaire_button: "Ejecutar Cuestionario"
  run_questionnaires_button: "Ejecutar Cuestionarios Seleccionados"
  rerun_button: "ğŸ” Re-ejecutar"
  clear_results_button: "ğŸ—‘ï¸ Limpiar Resultados"
  contacting_model: "Contactando modelo..."
  no_result_error: "No se devolviÃ³ resultado del modelo"
  results_summary: "ğŸ“‹ Resultados de Cuestionarios"
  scores_header: "Puntuaciones"
  score_distribution_header: "DistribuciÃ³n de PuntuaciÃ³n"
  model_reasoning_header: "Razonamiento del Modelo"
  no_scores_warning: "No se encontraron puntuaciones en la respuesta del modelo"
  question_column: "Pregunta"
  question_text_column: "Texto de Pregunta"
  score_column: "PuntuaciÃ³n"
  scale_column: "Escala"
  total_score_label: "PuntuaciÃ³n Total PCS"
  total_score_help: "Suma de todas las puntuaciones individuales (rango: 0-52)"
  results_header: "Resultados"
  scale_type_column: "Tipo de Escala"
  interference_average: "Promedio Interferencia"
  interference_help: "PuntuaciÃ³n promedio para Ã­tems de interferencia (0-10)"
  intensity_average: "Promedio Intensidad"
  intensity_help: "PuntuaciÃ³n promedio para Ã­tems de intensidad (0-10)"
  average_score_label: "PuntuaciÃ³n Promedio"
  tsk_total_help: "Suma de todas las puntuaciones TSK-11SV (rango: 11-44)"
  tsk_average_help: "PuntuaciÃ³n promedio TSK-11SV (rango: 1-4)"
  bpi_total_help: "Suma de todas las puntuaciones BPI-IS (rango: 0-100)"

analytics:
  header: "ğŸ“ˆ AnalÃ­ticas"
  description: "Ver analÃ­ticas e insights de sus datos de evaluaciÃ³n"
  group_summary: "Resumen del Grupo {group_id}"
  experiments_metric: "Experimentos"
  questionnaires_metric: "Cuestionarios"
  stored_results_header: "Resultados Almacenados"
  no_evaluation_history: "No hay historial de evaluaciÃ³n disponible para esta sesiÃ³n."
  total_evaluations: "Evaluaciones Totales"
  models_used: "Modelos Usados"
  avg_temperature: "Temperatura Promedio"
  last_24h: "Ãšltimas 24h"
  evaluation_trends: "ğŸ“ˆ Tendencias de EvaluaciÃ³n"
  score_distributions: "ğŸ“Š Distribuciones de PuntuaciÃ³n por DimensiÃ³n"
  consistency_analysis: "ğŸ¯ AnÃ¡lisis de Consistencia"
  consistency_warning: "Se necesitan al menos 2 evaluaciones para anÃ¡lisis de consistencia."
  model_comparison: "ğŸ¤– ComparaciÃ³n de Modelos"
  temporal_analysis: "â° AnÃ¡lisis Temporal"
  export_data: "ğŸ“¤ Exportar Datos"
  
management:
  header: "âš™ï¸ GestiÃ³n de AplicaciÃ³n"
  description: "Gestionar grupos de evaluaciÃ³n, ver informaciÃ³n del sistema y acceder a herramientas de administraciÃ³n."
  evaluation_groups_tab: "ğŸ§ª Grupos de EvaluaciÃ³n"
  user_administration_tab: "ğŸ‘¥ AdministraciÃ³n de Usuarios"
  questionnaire_prompts_tab: "ğŸ“ Prompts de Cuestionarios"
  system_info_tab: "ğŸ“Š InformaciÃ³n del Sistema"
  experiment_group_management: "ğŸ§ª GestiÃ³n de Grupos de EvaluaciÃ³n"
  select_group_info: "Seleccione un grupo de evaluaciÃ³n de la barra lateral para ver sus detalles."
  no_groups_admin: "ğŸ“­ No existen grupos de evaluaciÃ³n en el sistema aÃºn."
  no_groups_user: "ğŸ“­ No tienes grupos de evaluaciÃ³n aÃºn. Crea uno abajo para comenzar."
  create_new_group: "â• Crear Nuevo Grupo de EvaluaciÃ³n"
  create_tip: "ğŸ’¡ **Consejo**: DespuÃ©s de crear un nuevo grupo de evaluaciÃ³n, la pÃ¡gina se actualizarÃ¡ automÃ¡ticamente para actualizar todos los menÃºs desplegables en toda la aplicaciÃ³n."
  about_templates: "â„¹ï¸ Acerca de las Plantillas Predeterminadas"
  templates_description: |
    **Plantillas de EvaluaciÃ³n de Dolor CrÃ³nico Predeterminadas:**

    - **Rol del Sistema**: Define la IA como una persona experta  e en evaluaciÃ³n de los problemas de dolor
    - **Prompt Base**: Proporciona criterios de evaluaciÃ³n estructurados para puntuaciÃ³n de severidad y discapacidad (escala 0-10)
    - **Soporte de Idioma**: Optimizado para narrativas de pacientes en espaÃ±ol con explicaciones en inglÃ©s
    - **Enfoque ClÃ­nico**: Incluye orientaciÃ³n sobre mecanismos de afrontamiento, factores de resistencia y evaluaciÃ³n holÃ­stica

    Estas plantillas estÃ¡n basadas en mejores prÃ¡cticas clÃ­nicas y pueden personalizarse despuÃ©s de la creaciÃ³n.
  required_fields: "ğŸ“ **Campos Requeridos**: DescripciÃ³n y al menos una dimensiÃ³n completa (nombre y definiciÃ³n)"
  login_required: "ğŸ”’ Por favor inicie sesiÃ³n para acceder a las funciones de gestiÃ³n."
  error_loading: "âŒ Error al cargar la interfaz de gestiÃ³n: {error}"
  system_info_header: "ğŸ“Š InformaciÃ³n del Sistema"
  total_users_metric: "ğŸ‘¥ Usuarios Totales"
  total_groups_metric: "ğŸ§ª Grupos de EvaluaciÃ³n Totales"
  create_group_button: "ğŸš€ Crear Grupo de EvaluaciÃ³n"
  description_label: "DescripciÃ³n *"
  description_help: "Una breve descripciÃ³n para quÃ© es este grupo de evaluaciÃ³n"
  system_role_label: "Rol del Sistema (Opcional)"
  system_role_help: "Defina el rol/contexto para el sistema de IA"
  base_prompt_label: "Plantilla de Prompt Base (Opcional)"
  base_prompt_help: "Instrucciones base que se usarÃ¡n para todas las evaluaciones en este grupo"
  group_created_success: "âœ… Â¡Grupo de evaluaciÃ³n creado exitosamente!"
  group_creation_error: "âŒ Error al crear grupo de evaluaciÃ³n"
  admin_panel: "ğŸ‘‘ Panel de AdministraciÃ³n"
  user_management: "ğŸ‘¥ GestiÃ³n de Usuarios"
  experiment_groups: "ğŸ§ª Grupos de Experimentos"
  basic_information: "ğŸ“‹ InformaciÃ³n BÃ¡sica"
  group_id: "ğŸ†” ID del Grupo"
  status_concluded: "âœ… Concluido"
  status_active: "ğŸ”„ Activo"
  created_label: "Creado"
  owner_label: "Propietario"
  no_description: "Sin descripciÃ³n proporcionada"
  ai_configuration: "ğŸ¤– ConfiguraciÃ³n de IA"
  system_role_content: "Contenido del Rol del Sistema"
  no_system_role: "_No se definiÃ³ rol del sistema_"
  view_system_role: "Ver Rol del Sistema"
  view_base_prompt: "Ver Prompt Base"
  base_prompt_content: "Contenido del Prompt Base"
  no_base_prompt: "_No se definiÃ³ prompt base_"
  evaluation_dimensions: "ğŸ“Š Dimensiones de EvaluaciÃ³n"
  no_dimensions: "_No se definieron dimensiones_"
  generated_prompt: "ğŸ¯ Prompt de EvaluaciÃ³n Generado"
  no_generated_prompt: "_No se puede generar prompt sin dimensiones_"
  questionnaire_prompts_header: "ğŸ“ GestiÃ³n de Prompts de Cuestionarios"
  questionnaire_prompts_description: "Personaliza los prompts de cuestionarios para grupos de evaluaciÃ³n especÃ­ficos. Cada grupo puede tener roles de sistema e instrucciones personalizadas para cuestionarios PCS, BPI-IS y TSK-11SV."
  select_experiment_group: "ğŸ§ª Seleccionar Grupo de EvaluaciÃ³n"
  initialize_default_prompts: "ğŸ”§ Inicializar Prompts Predeterminados"
  prompts_initialized: "âœ… Â¡Prompts predeterminados inicializados exitosamente!"
  prompts_initialization_failed: "âŒ Error al inicializar prompts predeterminados."
  current_prompts: "ğŸ“‹ Prompts Actuales"
  questionnaire_prompts: "Prompts de Cuestionarios"
  system_role: "Rol del Sistema"
  instructions: "Instrucciones"
  save_prompts: "ğŸ’¾ Guardar Prompts"
  prompts_updated: "prompts actualizados exitosamente!"
  prompts_update_failed: "fallÃ³ la actualizaciÃ³n de prompts."
  reset_to_default: "ğŸ”„ Restablecer por Defecto"
  prompts_reset: "prompts restablecidos por defecto exitosamente!"
  prompts_reset_failed: "fallÃ³ el restablecimiento de prompts."
  no_experiment_groups: "âš ï¸ No se encontraron grupos de evaluaciÃ³n. Crea un grupo de evaluaciÃ³n primero."
  
help:
  header: "â“ Ayuda y DocumentaciÃ³n"
  description: "Aprenda cÃ³mo usar la Plataforma de EvaluaciÃ³n AINarratives"
  
common:
  loading: "Cargando..."
  error: "Error"
  success: "Ã‰xito"
  warning: "Advertencia"
  info: "InformaciÃ³n"
  cancel: "Cancelar"
  save: "Guardar"
  delete: "Eliminar"
  edit: "Editar"
  view: "Ver"
  close: "Cerrar"
  back: "AtrÃ¡s"
  next: "Siguiente"
  previous: "Anterior"
  submit: "Enviar"
  reset: "Restablecer"
  clear: "Limpiar"
  search: "Buscar"
  filter: "Filtrar"
  sort: "Ordenar"
  export: "Exportar"
  import: "Importar"
  download: "Descargar"
  upload: "Subir"
  connections_initialized: "âœ… Â¡Conexiones inicializadas exitosamente!"
  connection_failed: "âŒ ConexiÃ³n fallÃ³: {error}"
  
errors:
  api_key_required: "âŒ Por favor ingrese su clave API de OpenAI para continuar"
  database_error: "Error de conexiÃ³n a base de datos"
  json_parsing_failed: "FallÃ³ el anÃ¡lisis JSON. Intentando extraer valores del contenido sin procesar."
  file_processing_failed: "Error al procesar archivo: {error}"

# Display Components
display:
  consistency_analysis: "ğŸ¯ AnÃ¡lisis de Consistencia"
  consistency_warning: "Se necesitan al menos 2 evaluaciones para anÃ¡lisis de consistencia."
  avg_std_dev: "DesviaciÃ³n EstÃ¡ndar Promedio"
  max_difference: "Diferencia MÃ¡xima"
  dimensions_analyzed: "Dimensiones Analizadas"
  batch_processing_progress: "ğŸ”„ Progreso de Procesamiento por Lotes"
  evaluation_comparison: "ComparaciÃ³n de Evaluaciones"
  no_comparison_data: "No hay datos de evaluaciÃ³n vÃ¡lidos para comparaciÃ³n"
  comparison_info: "Se necesitan al menos 2 evaluaciones para comparaciÃ³n"
  no_batch_results: "No hay resultados por lotes para mostrar"
  total_evaluations: "Evaluaciones Totales"
  successful_evaluations: "Exitosas"
  error_rate: "Tasa de Error"
  score_distributions: "Distribuciones de PuntuaciÃ³n"
  scores_by_category: "Puntuaciones por CategorÃ­a"
  configuration: "ConfiguraciÃ³n"
  input_narrative: "Narrativa de Entrada"
  evaluation_result: "Resultado de EvaluaciÃ³n"
  model_reasoning: "Razonamiento del Modelo"
  dimension_explanations: "Explicaciones de Dimensiones"
  prompt_preview: "Vista Previa del Prompt"
  cost_estimate: "ğŸ’° EstimaciÃ³n de Costo"

# Hardcoded strings that need localization
ui_text:
  batch_processing_progress: "ğŸ”„ Progreso de Procesamiento por Lotes"
  customize_evaluation_dimensions: "### ğŸ“ Personalizar Dimensiones de EvaluaciÃ³n"
  modify_dimensions_info: "ğŸ’¡ Modifique las dimensiones a continuaciÃ³n para personalizar cÃ³mo se evaluarÃ¡n las narrativas."
  define_evaluation_dimensions: "Defina las dimensiones de evaluaciÃ³n. El prompt subyacente proviene del grupo de evaluaciÃ³n seleccionado."
  fix_dimension_ranges: "âŒ Por favor corrija los rangos de dimensiÃ³n antes de continuar."
  no_permission_update: "âŒ No tienes permisos para actualizar este grupo de evaluaciÃ³n."
  changes_saved_locally: "Cambios guardados localmente solo para esta sesiÃ³n."
  dimensions_updated_success: "âœ… Â¡Dimensiones actualizadas exitosamente!"
  database_update_failed_local_saved: "âš ï¸ No se pudo actualizar el grupo de evaluaciÃ³n en la base de datos. Cambios guardados localmente para esta sesiÃ³n."
  error_updating_group: "âŒ Error al actualizar el grupo de evaluaciÃ³n: {error}"
  translating_result: "ğŸŒ Traduciendo resultado de evaluaciÃ³n a {language}..."
  translation_completed_success: "âœ… Â¡TraducciÃ³n a {language} completada exitosamente!"
  translation_failed_english_only: "âš ï¸ Error en la traducciÃ³n: {error}. Continuando solo con inglÃ©s."
  evaluation_completed_success: "âœ… Â¡EvaluaciÃ³n completada exitosamente!"
  batch_evaluation_header: "ğŸ“¦ EvaluaciÃ³n por Lotes"
  upload_data_header: "ğŸ“ Subir Datos"
  upload_csv_info: "Suba un archivo CSV o use datos de muestra para probar."
  login_required_management: "ğŸ”’ Por favor inicie sesiÃ³n para acceder a las funciones de gestiÃ³n."
  define_evaluation_dimensions_title: "**Definir Dimensiones de EvaluaciÃ³n**"
  dimension_name_title: "**Nombre de DimensiÃ³n**"
  definition_explanation_title: "**DefiniciÃ³n/ExplicaciÃ³n**"
  lowest_score_title: "**PuntuaciÃ³n MÃ­nima**"
  highest_score_title: "**PuntuaciÃ³n MÃ¡xima**"
  actions_title: "**Acciones**"
  generated_prompt_preview: "### ğŸ“‹ Vista Previa del Prompt Generado"
  add_dimension_button: "â• Agregar DimensiÃ³n"
  use_this_prompt_button: "Usar Este Prompt"
  delete_prompt_button: "Eliminar Prompt"
  add_json_structure_button: "Agregar Estructura JSON"
  add_scale_definition_button: "Agregar DefiniciÃ³n de Escala"
  add_medical_context_button: "Agregar Contexto MÃ©dico"
  no_saved_prompts_info: "No hay prompts guardados disponibles."
  no_prompts_in_category_info: "No hay prompts en la categorÃ­a seleccionada."
  no_prompt_history_info: "No hay historial de uso de prompts disponible."
  prompt_deleted_success: "Â¡Prompt eliminado!"
  confirm_deletion_warning: "Haz clic de nuevo para confirmar la eliminaciÃ³n"
  provide_name_error: "Por favor proporciona un nombre para el prompt"
  provide_description_error: "Por favor proporciona una descripciÃ³n"
  prompt_saved_success: "âœ… Â¡Prompt '{prompt_name}' guardado exitosamente!"
  placeholder_required_error: "âš ï¸ El prompt debe contener el marcador {narrative}"
  potential_issues_warning: "**Problemas Potenciales:**"
  prompt_looks_good: "âœ… Â¡El prompt se ve bien!"
  
  # UI Component Headers
  save_current_prompt_header: "ğŸ’¾ Guardar Prompt Actual"
  advanced_prompt_editor_header: "âœï¸ Editor Avanzado de Prompts"
  prompt_analytics_header: "ğŸ“Š AnalÃ­ticas de Prompts"
  prompt_customization_header: "ğŸ”§ PersonalizaciÃ³n de Prompts"
  user_administration_header: "ğŸ‘¥ AdministraciÃ³n de Usuarios"
  all_users_subheader: "ğŸ“Š Todos los Usuarios"
  detailed_results_header: "ğŸ“‹ Resultados Detallados"
  available_variables_header: "Variables Disponibles"
  prompt_validation_header: "ValidaciÃ³n de Prompt"
  most_used_prompts_header: "Prompts MÃ¡s Utilizados"
  your_account_header: "ğŸ‘¤ Tu Cuenta"
  database_connection_header: "ğŸ”— ConexiÃ³n a Base de Datos"
  documentation_header: "ğŸ“š DocumentaciÃ³n"
  quick_actions_header: "âš¡ Acciones RÃ¡pidas"
  
  # Button Text
  dimensions_ready_button: "âœ… DefiniciÃ³n de Dimensiones Lista"
  start_batch_processing_button: "ğŸš€ Iniciar Procesamiento por Lotes"
  use_sample_data_button: "ğŸ§ª Usar Datos de Muestra"
  process_sample_data_button: "Procesar Datos de Muestra"
  show_complete_prompt_button: "ğŸ“‹ Mostrar Prompt Completo"
  
  # Form Elements
  filter_by_category_label: "Filtrar por categorÃ­a:"
  prompt_name_label: "Nombre del Prompt"
  custom_category_label: "CategorÃ­a Personalizada (si se seleccionÃ³ 'personalizada')"
  show_debug_info_label: "ğŸ” Mostrar InformaciÃ³n de DepuraciÃ³n de Dimensiones"
  narrative_text_label: "Texto de Narrativa"
  description_label_short: "DescripciÃ³n"
  
  # Placeholders
  custom_evaluation_placeholder: "ej., Mi EvaluaciÃ³n Personalizada"
  prompt_purpose_placeholder: "Breve descripciÃ³n del propÃ³sito de este prompt"
  study_description_placeholder: "ej., Estudio de EvaluaciÃ³n de Dolor "
  system_role_placeholder: "Eres un  experto especializado en evaluaciÃ³n del dolor..."
  base_prompt_placeholder: "EvalÃºa la siguiente narrativa de dolor y proporciona puntuaciones para severidad y discapacidad..."
  
  # Help Text
  category_organization_help: "Elige o agrega una categorÃ­a para organizaciÃ³n"
  narrative_placeholder_help: "Usa {narrative} como marcador para el texto de la narrativa"
  csv_format_help: "El CSV debe contener columnas: 'id', 'narrative', y opcionalmente 'category'"
  expert_prompts_help: "Pre-cargar con prompts diseÃ±ados por expertos para evaluaciÃ³n de dolor"
  ai_role_help: "Define el rol y experiencia de la IA (opcional)"
  prompt_template_help: "Plantilla de prompt predeterminada para evaluaciones (opcional)"
  remove_dimension_help: "Eliminar {dimension_name}"
  select_for_removal_label: "Seleccionar para eliminar"
  remove_selected_dimensions_button: "ğŸ—‘ï¸ Eliminar Dimensiones Seleccionadas"
  no_dimensions_selected_warning: "Por favor seleccione al menos una dimensiÃ³n para eliminar."
  confirm_remove_dimensions: "Â¿EstÃ¡ seguro de que desea eliminar {count} dimensiÃ³n(es) seleccionada(s)?"
  dimensions_removed_success: "âœ… Las dimensiones seleccionadas han sido eliminadas."
  dimensions_removed_and_saved_success: "âœ… Las dimensiones seleccionadas han sido eliminadas y guardadas en la base de datos."
  dimensions_save_failed: "âŒ Error al guardar los cambios de dimensiones en la base de datos."
  dimensions_removed_no_db: "âœ… Dimensiones eliminadas (base de datos no conectada)."
  dimensions_save_error: "âŒ Error al guardar en la base de datos"
  
  # Info Messages
  admin_see_all_groups_info: "ğŸ‘‘ Como administrador, puedes ver todos los grupos de evaluaciÃ³n."
  admin_privileges_required_warning: "ğŸ”’ Se requieren privilegios de administrador para acceder a la administraciÃ³n de usuarios."
  no_users_found_info: "ğŸ“­ No se encontraron usuarios en el sistema."
  upload_csv_sample_info: "Sube un archivo CSV o usa datos de muestra para probar."
  command_line_scripts_info: "ğŸ’¡ Usa los scripts de lÃ­nea de comandos para operaciones detalladas de gestiÃ³n de usuarios."
  
  # User Management
  user_management_actions: "Acciones"
  user_actions_header: "Acciones de Usuario"
  create_new_user_header: "â• Crear Nuevo Usuario"
  username_input_label: "Nombre de Usuario"
  password_input_label: "ContraseÃ±a"
  make_admin_checkbox: "Hacer Administrador"
  create_user_button: "Crear Usuario"
  user_created_success: "âœ… Usuario '{username}' creado exitosamente"
  user_creation_failed: "âŒ Error al crear usuario: {error}"
  username_required_error: "El nombre de usuario es requerido"
  password_required_error: "La contraseÃ±a es requerida"
  password_min_length_error: "La contraseÃ±a debe tener al menos 3 caracteres"
  edit_user_header: "âœï¸ Editar Usuario: {username}"
  delete_user_button: "ğŸ—‘ï¸ Eliminar Usuario"
  toggle_admin_button: "ğŸ‘‘ Cambiar Admin"
  reset_password_button: "ğŸ”‘ Restablecer ContraseÃ±a"
  new_password_label: "Nueva ContraseÃ±a"
  confirm_delete_user: "Â¿EstÃ¡ seguro de que desea eliminar al usuario '{username}'? Esta acciÃ³n no se puede deshacer."
  user_deleted_success: "âœ… Usuario '{username}' eliminado exitosamente"
  user_delete_failed: "âŒ Error al eliminar usuario: {error}"
  admin_status_updated: "âœ… Estado de administrador actualizado para el usuario '{username}'"
  admin_update_failed: "âŒ Error al actualizar estado de administrador: {error}"
  password_reset_success: "âœ… ContraseÃ±a restablecida exitosamente para el usuario '{username}'"
  password_reset_failed: "âŒ Error al restablecer contraseÃ±a: {error}"
  cannot_delete_self: "âŒ No puede eliminar su propia cuenta"
  experiment_groups_column: "Grupos de Experimento"
  edit_experiment_groups_header: "ğŸ§ª Editar Grupos de Experimento"
  edit_groups_button: "ğŸ§ª Editar Grupos"
  current_groups_label: "Grupos Actuales"
  enter_group_ids_label: "Ingrese IDs de Grupo (separados por comas)"
  enter_group_ids_help: "Ingrese los IDs de grupos de experimento separados por comas (ej. 1, 3, 5)"
  save_groups_button: "ğŸ’¾ Guardar Grupos"
  groups_updated_success: "âœ… Grupos de experimento actualizados exitosamente para el usuario '{username}'"
  groups_update_failed: "âŒ Error al actualizar grupos de experimento: {error}"
  invalid_group_ids_error: "âŒ Formato invÃ¡lido: Por favor ingrese enteros separados por comas"
  group_not_found_error: "âŒ El grupo de experimento con ID {group_id} no existe"
  available_groups_label: "ğŸ“‹ Grupos Disponibles"
  no_groups_available: "No hay grupos de experimento disponibles"
  
  # Error Messages
  invalid_json_response_error: "Formato de respuesta invÃ¡lido: se esperaba objeto JSON"
  missing_scores_field_error: "Formato de respuesta invÃ¡lido: falta el campo 'scores'"
  scores_not_object_error: "Formato de respuesta invÃ¡lido: 'scores' debe ser un objeto"
  json_parsing_failed_warning: "FallÃ³ el anÃ¡lisis JSON. Intentando extraer valores del contenido sin procesar."
  invalid_json_file_error: "Archivo JSON invÃ¡lido"
  fix_issues_error: "âŒ Por favor corrije los siguientes problemas:"
  
  # Generated Prompt Preview
  generated_prompt_preview_header: "**Vista Previa del Prompt Generado:**"
  define_dimensions_header: "**Definir Dimensiones de EvaluaciÃ³n**"
  prompt_preview_header: "**Vista Previa del Prompt**"
  
  # Success Messages
  prompt_saved_session_success: "Prompt guardado como prompt actual."
  prompt_library_header: "ğŸ“š Biblioteca de Prompts"
  consistency_analysis_header: "ğŸ¯ AnÃ¡lisis de Consistencia"
  consistency_analysis_warning: "Se necesitan al menos 2 evaluaciones para anÃ¡lisis de consistencia."
  invalid_response_format: "Formato de respuesta invÃ¡lido: se esperaba objeto JSON"
  model_format_error: "Por favor intente de nuevo. Si el problema persiste, el modelo podrÃ­a no estar siguiendo el formato JSON."
  latest_evaluation_results: "ğŸ¯ Resultados de EvaluaciÃ³n MÃ¡s Recientes"
  batch_results_summary: "ğŸ“Š Resumen de Resultados por Lotes"
  detailed_results: "ğŸ“‹ Resultados Detallados"

evaluation:
   no_numeric_scores: "No se encontraron puntuaciones numÃ©ricas en el resultado de evaluaciÃ³n"
   narrative_text: "Texto de Narrativa"
   details_header: "Detalles de EvaluaciÃ³n"
   configuration_header: "ConfiguraciÃ³n"
   input_narrative_header: "Narrativa de Entrada"
   result_header: "Resultado de EvaluaciÃ³n"
   reasoning_header: "Razonamiento del Modelo"
   model_reasoning_header: "Razonamiento del Modelo"
   explanations_header: "Explicaciones de Dimensiones"
   raw_response_header: "Respuesta Cruda de API"
   model_label: "Modelo"
   temperature_label: "Temperatura"
   timestamp_label: "Marca de Tiempo"
   max_tokens_label: "MÃ¡ximo de Tokens"
   narrative_text_label: "Texto de Narrativa"
   no_narrative_available: "No hay narrativa disponible"

assessment_feedback:
   header: "Feedback experto"
   instructions: |
     Por favor proporciona tu feedback para cada una de las dimensiones evaluadas. Califica la puntuaciÃ³n otorgada para cada dimensiÃ³n, la explicaciÃ³n facilitada
     y hasta quÃ© punto  utilizarÃ­as esa informaciÃ³n en tu valoraciÃ³n clÃ­nica.
   dimension_group_header: "EvaluaciÃ³n de {dimension}"
   dimension_score_question: "La puntuaciÃ³n representa adecuadamente la {dimension} expresada en la narrativa."
   dimension_explanation_question: "La explicaciÃ³n representa adecuadamente la {dimension} expresada en la narrativa."
   dimension_usage_question: "UsarÃ­a la puntuaciÃ³n y explicaciÃ³n de {dimension} para ayudarme en la evlauaciÃ³n del dolor del paciente."
   submit_button: "Enviar feedback"
   feedback_completed: "âœ… Feedback completado"
   already_submitted_info: "Ya registraste feedback para esta evaluaciÃ³n."
   save_success: "âœ… Feedback guardado correctamente."
   save_error: "âŒ No se pudo guardar el feedback: {error}"
   incomplete_warning: "âš ï¸ Responde todas las preguntas antes de enviar."
   no_database_warning: "â„¹ï¸ La recopilaciÃ³n de feedback requiere una conexiÃ³n activa a la base de datos."
   no_experiment_info: "â„¹ï¸ Ejecuta y guarda una evaluaciÃ³n antes de proporcionar feedback."
   select_placeholder: "Selecciona una opciÃ³n"
   options:
     strongly_disagree: "Totalmente en desacuerdo"
     disagree: "En desacuerdo"
     somewhat_disagree: "Algo en desacuerdo"
     neither_agree_nor_disagree: "Ni de acuerdo ni en desacuerdo"
     somewhat_agree: "Algo de acuerdo"
     agree: "De acuerdo"
     strongly_agree: "Totalmente de acuerdo"

questionnaire_feedback:
  header: "Feedback experto sobre cuestionario"
  instructions: |
    Considerando la narrativa y las respuestas al cuestionario proporcionadas por el sistema, proporciona tu evaluaciÃ³n de experto.
  expert_instructions: "Instrucciones para el Experto"
  authenticity_question: "Â¿Consideras que el cuestionario podrÃ­a haber sido contestado por la persona que escribiÃ³ la narrativa?"
  reasoning_question: "Â¿El razonamiento del modelo justifica adecuadamente las respuestas al cuestionario basÃ¡ndose en el contenido de la narrativa?"
  submit_button: "Enviar feedback"
  feedback_completed: "âœ… Feedback completado"
  already_submitted_info: "Ya registraste feedback para este cuestionario."
  save_success: "âœ… Feedback del cuestionario guardado correctamente."
  save_error: "âŒ No se pudo guardar el feedback del cuestionario: {error}"
  incomplete_warning: "âš ï¸ Responde todas las preguntas antes de enviar."
  no_database_warning: "â„¹ï¸ La recopilaciÃ³n de feedback requiere una conexiÃ³n activa a la base de datos."
  no_questionnaire_info: "â„¹ï¸ Ejecuta y guarda un cuestionario antes de proporcionar feedback."
  select_placeholder: "Selecciona una opciÃ³n"
  options:
    strongly_disagree: "Totalmente en desacuerdo"
    disagree: "En desacuerdo"
    somewhat_disagree: "Algo en desacuerdo"
    neither_agree_nor_disagree: "Ni de acuerdo ni en desacuerdo"
    somewhat_agree: "Algo de acuerdo"
    agree: "De acuerdo"
    strongly_agree: "Totalmente de acuerdo"

# Welcome page (landing page for non-authenticated users)
welcome:
  tagline: "Herramienta de InvestigaciÃ³n Potenciada por IA para la EvaluaciÃ³n de Dimensiones de Dolor CrÃ³nico"
  description: |
    Una plataforma para profesionales de la salud e investigadores para ayudar en la evaluaciÃ³n del dolor
    de las narrativas propias de las personas. AI Narratives utiliza Modelos de Lenguaje Grande y ha sido optimizado
    para el idioma espaÃ±ol. Construido con prÃ¡cticas modernas de Python incluyendo SQLModel, gestiÃ³n de paquetes UV,
    y gestiÃ³n integral de usuarios para la excelencia en investigaciÃ³n.
  about_platform_title: "Acerca de Esta Plataforma"
  about_platform_description: |
    La Plataforma de EvaluaciÃ³n AINarratives es una herramienta de investigaciÃ³n especializada diseÃ±ada para profesionales
    de la salud e investigadores para analizar sistemÃ¡ticamente las descripciones de dolor 
    utilizando inteligencia artificial con criterios de evaluaciÃ³n a nivel de psicÃ³logo experto.
  key_capabilities_title: "Capacidades Clave:"
  capability_management: "âš™ï¸ **GestiÃ³n**: Crear y gestionar grupos de evaluaciÃ³n para investigaciÃ³n organizada"
  capability_evaluation: "**EvaluaciÃ³n de resultados relevantes para evaluaciÃ³n de Dimensiones**: los expertos pueden elegir entre evaluaciones predefinidas o crear las suyas propias."
  capability_spanish: "**Optimizado para Idioma EspaÃ±ol**: DiseÃ±ado especÃ­ficamente para narrativas de pacientes de habla hispana"
  capability_batch: "ğŸ©º **AnÃ¡lisis individuales o por lotes**: puedes usar AINarratives para evaluar narrativas individuales o un conjunto que incluya diferentes."
  capability_analytics: "ğŸ“Š **AnÃ¡lisis e Insights**: Analizar patrones y exportar datos para anÃ¡lisis externos"
  capability_help: "ğŸ“š **Ayuda y DocumentaciÃ³n**: GuÃ­as integrales y mejores prÃ¡cticas"
  quick_start_title: "Inicio RÃ¡pido:"
  quick_start_step1: "1. **Iniciar sesiÃ³n** usando la barra lateral"
  quick_start_step2: "2. **Configurar** tu clave de API de OpenAI"
  quick_start_step3: "3. **Crear** un grupo de EvaluaciÃ³n"
  quick_start_step4: "4. **Comenzar** a evaluar narrativas"
  need_help_title: "Â¿Necesitas Ayuda?"
  need_help_item1: "- Consulta la pestaÃ±a de Ayuda despuÃ©s de iniciar sesiÃ³n"
  need_help_item2: "- Revisa la documentaciÃ³n"
  need_help_item3: "- Contacta a tu administrador"
  for_administrators_title: "Para Administradores:"
  for_administrators_description: |
    Usa los scripts de gestiÃ³n para:
    - Registrar nuevos usuarios
    - Gestionar permisos de usuario
    - Respaldar datos de evaluaciÃ³n

    Ver docs/archive/USER_MANAGEMENT.md para detalles.
  getting_started_title: "Comenzando"
  getting_started_description: |
    **Para comenzar a usar la plataforma:**
    1. **Iniciar sesiÃ³n** con tus credenciales usando la barra lateral de la izquierda
    2. Todas las herramientas y caracterÃ­sticas de evaluaciÃ³n estarÃ¡n disponibles despuÃ©s de la autenticaciÃ³n
    3. Comienza con la pestaÃ±a de GestiÃ³n para crear tu primer grupo de EvaluaciÃ³n
    4. Visita la pestaÃ±a de Ayuda y DocumentaciÃ³n para orientaciÃ³n detallada

    **Contacta a tu administrador del sistema si necesitas credenciales de acceso o soporte tÃ©cnico.**

  # Additional Management UI Strings
  use_default_templates_label: "Usar plantillas de evaluaciÃ³n de dolor crÃ³nico predeterminadas"
  grant_access_users_label: "Conceder acceso a usuarios"
  user_management_scripts_header: "**Scripts de GestiÃ³n de Usuarios:**"
  user_registration_header: "**Registro de Usuarios:**"
  your_access_metric: "ğŸ” Tu Acceso"
  all_groups_admin: "Todos los Grupos (Administrador)"
  your_groups_metric: "ğŸ§ª Tus Grupos"
  username_label: "**Nombre de Usuario:**"
  user_id_label: "**ID de Usuario:**"
  account_type_label: "**Tipo de Cuenta:**"
  admin_type: "Administrador"
  regular_user_type: "Usuario Regular"
  permissions_label: "**Permisos:**"
  access_all_groups_perm: "âœ… Acceder a todos los grupos de EvaluaciÃ³n"
  manage_users_perm: "âœ… Gestionar usuarios"
  system_admin_perm: "âœ… AdministraciÃ³n del sistema"
  create_groups_perm: "âœ… Crear grupos de EvaluaciÃ³n"
  run_evaluations_perm: "âœ… Ejecutar evaluaciones"
  manage_data_perm: "âœ… Gestionar tus datos"
  schema_label: "**Esquema:**"
  status_label: "**Estado:**"
  connected_status: "âœ… Conectado"
  
  # Spinner Messages
  evaluating_narrative_spinner: "Evaluando narrativa..."
  evaluating_multiple_consistency_spinner: "Evaluando mÃºltiples veces para consistencia..."
  
  # Metric Labels
  characters_metric: "Caracteres"
  estimated_tokens_metric: "Tokens Estimados"
  score_range_metric: "Rango de PuntuaciÃ³n"
  total_uses_metric: "Usos Totales"
  unique_prompts_metric: "Prompts Ãšnicos"
  uses_today_metric: "Usos Hoy"
  total_evaluations_metric: "Evaluaciones Totales"
  successful_metric: "Exitosas"
  error_rate_metric: "Tasa de Error"
  input_cost_metric: "Costo de Entrada"
  output_cost_metric: "Costo de Salida"
  total_cost_metric: "Costo Total"
  
  # Form Labels
  save_prompt_button: "Guardar Prompt"
  add_dimension_button: "Agregar DimensiÃ³n"
  
  # Section Headers
  score_distributions_header: "Distribuciones de PuntuaciÃ³n"
  scores_by_category_header: "Puntuaciones por CategorÃ­a"
  evaluation_details_header: "Detalles de EvaluaciÃ³n"
  configuration_header: "ConfiguraciÃ³n"
  input_narrative_header: "Narrativa de Entrada"
  evaluation_result_header: "Resultado de EvaluaciÃ³n"
  model_reasoning_header: "Razonamiento del Modelo"
  dimension_explanations_header: "Explicaciones de Dimensiones"
  raw_api_response_header: "Respuesta Cruda de API"
  prompt_preview_header: "Vista Previa del Prompt"
  preview_prompt_header: "Vista Previa del Prompt"
  
  # Warning/Error Messages
  invalid_response_format_warning: "Formato de respuesta invÃ¡lido: se esperaba objeto JSON"
  missing_scores_field_warning: "Formato de respuesta invÃ¡lido: falta el campo 'scores'"
  scores_not_object_warning: "Formato de respuesta invÃ¡lido: 'scores' debe ser un objeto"
  model_format_error_message: "Por favor intente de nuevo. Si el problema persiste, el modelo podrÃ­a no estar siguiendo el formato JSON."
  cost_estimate_not_available: "EstimaciÃ³n de costo no disponible para este modelo."

# Footer
footer:
  version: "Plataforma de EvaluaciÃ³n AINarratives v0.1.0"
  built_with: "Construido con Streamlit, SQLModel y OpenAI"
  tagline_footer: "Excelencia en InvestigaciÃ³n a travÃ©s de IA Moderna"